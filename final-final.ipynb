{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# GLOBAL WARNING CONTROL (SAFE & CLEAN)\n",
    "# ==========================================\n",
    "import warnings\n",
    "\n",
    "# 1️⃣ Ignore known, harmless FutureWarnings (seaborn / pandas)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning\n",
    ")\n",
    "\n",
    "# 2️⃣ Ignore pandas RuntimeWarnings from NaN comparisons\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=RuntimeWarning,\n",
    "    module=\"pandas\"\n",
    ")\n",
    "\n",
    "# 3️⃣ Ignore seaborn warnings (visualization only)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    module=\"seaborn\"\n",
    ")\n",
    "\n",
    "# 4️⃣ Safety: ensure numpy doesn't spam invalid comparisons\n",
    "np.seterr(invalid='ignore')\n",
    "\n",
    "train=pd.read_csv(\"/kaggle/input/final-everything/train.csv\")\n",
    "test=pd.read_csv(\"/kaggle/input/final-everything/test.csv\")\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "test.isnull().sum()\n",
    "\n",
    "train = train.dropna(subset=['fruit_name']) #output label\n",
    "\n",
    "test_id=test['id']\n",
    "test=test.drop(columns=['id'])\n",
    "\n",
    "X=train.drop(columns=['fruit_name'])\n",
    "y=train['fruit_name']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
    "\n",
    "numeric_features=X.select_dtypes(include=['int64','float64']).columns\n",
    "categorical_features=X.select_dtypes(include=['object','category']).columns\n",
    "\n",
    "numerical_pipeline=Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='mean')),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "categorical_pipeline=Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encode',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#VISUALISAION\n",
    "# STEP 1: HISTPLOT\n",
    "# ==========================================\n",
    "print(\"Step 1: Histplots\")\n",
    "for col in numeric_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(X[col].dropna(), kde=True, color='royalblue')\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: TARGET COUNTS\n",
    "# ==========================================\n",
    "print(\"\\nStep 2: Target Counts\")\n",
    "print(y.value_counts())\n",
    "sns.countplot(x=y)\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: BOXPLOT (Before)\n",
    "# ==========================================\n",
    "print(\"\\nStep 3: Boxplots (Before)\")\n",
    "for col in numeric_features:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    sns.boxplot(x=X[col], color='tomato')\n",
    "    plt.show()\n",
    "    \n",
    "# ==========================================\n",
    "# STEP 4: OUTLIER & INF HANDLING (ROBUST VERSION)\n",
    "# ==========================================\n",
    "print(\"\\nStep 4: Handling Outliers & Converting Infinity to NaN\")\n",
    "\n",
    "# 1️⃣ Replace inf → NaN\n",
    "X_train[numeric_features] = X_train[numeric_features].replace([np.inf, -np.inf], np.nan)\n",
    "X_test[numeric_features]  = X_test[numeric_features].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 2️⃣ Compute IQR on TRAIN\n",
    "Q1 = X_train[numeric_features].quantile(0.25)\n",
    "Q3 = X_train[numeric_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 3️⃣ Keep only valid columns (IQR > 0 and not NaN)\n",
    "valid_cols = IQR[(IQR > 0) & (~IQR.isna())].index\n",
    "\n",
    "# 4️⃣ Clip only valid columns\n",
    "lower = Q1[valid_cols] - 1.5 * IQR[valid_cols]\n",
    "upper = Q3[valid_cols] + 1.5 * IQR[valid_cols]\n",
    "\n",
    "X_train[valid_cols] = X_train[valid_cols].clip(lower, upper, axis=1)\n",
    "X_test[valid_cols]  = X_test[valid_cols].clip(lower, upper, axis=1)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 5: RE-CHECK TARGET COUNTS\n",
    "# ==========================================\n",
    "print(f\"Total Unique Classes: {y.nunique()}\")\n",
    "print(\"-\" * 30)\n",
    "print(y.value_counts())\n",
    "\n",
    "# ==========================================\n",
    "# STEP 6: RE-CHECK BOXPLOTS (AFTER CLEANING)\n",
    "# ==========================================\n",
    "print(\"\\nStep 6: Final Visual Checks\")\n",
    "\n",
    "for col in numeric_features:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    sns.boxplot(x=X_train[col], color='limegreen')\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "    plt.show()\n",
    "    \n",
    "# ==========================================\n",
    "# STEP 7: NORMAL PAIRPLOT\n",
    "# ==========================================\n",
    "print(\"\\nStep 7: Generating Normal Pairplot\")\n",
    "\n",
    "plot_df = pd.concat([X_train, y_train], axis=1).sample(\n",
    "    min(500, len(X_train)),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sns.pairplot(plot_df, hue='fruit_name')\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 8: HEATMAP (Fixed)\n",
    "# ==========================================\n",
    "print(\"\\nStep 8: Corrected Heatmap\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X.corr(numeric_only=True), annot=True, cmap='RdYlBu', center=0, square=True)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "preprocessing=ColumnTransformer(transformers=[\n",
    "    ('num',numerical_pipeline,numeric_features),\n",
    "    ('cat',categorical_pipeline,categorical_features)\n",
    "])\n",
    "\n",
    "pipeline=Pipeline(steps=[\n",
    "    ('preprocessor',preprocessing),\n",
    "    ('model',model)\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)  # fit on train\n",
    "y_test_enc = le.transform(y_test)        # transform test\n",
    "\n",
    "pipeline.fit(X_train,y_train_enc)\n",
    "\n",
    "# Predict class labels\n",
    "y_pred = pipeline.predict(X_test)\n",
    "# Predict class probabilities (needed for log-loss, AUC, calibration)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test_enc, y_pred)\n",
    "\n",
    "# Log Loss\n",
    "ll = log_loss(y_test_enc, y_pred_proba)\n",
    "\n",
    "# Precision, Recall, F1 (weighted = handles class imbalance)\n",
    "prec = precision_score(y_test_enc, y_pred, average='weighted')\n",
    "rec  = recall_score(y_test_enc, y_pred, average='weighted')\n",
    "f1   = f1_score(y_test_enc, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Log Loss :\", ll)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1 Score :\", f1)\n",
    "\n",
    "\n",
    "final_preds=pipeline.predict(test)\n",
    "final_probs=pipeline.predict_proba(test)\n",
    "\n",
    "# ==========================================\n",
    "# STEP 10: FINAL DATA PREPARATION\n",
    "# (NO ROW DROPPED, NO NaNs INTRODUCED)\n",
    "# ==========================================\n",
    "print(\"\\nStep 10: Preparing Final Submission DataFrames...\")\n",
    "# Decode predicted labels\n",
    "decoded_labels = le.inverse_transform(final_preds)\n",
    "# Highest confidence per row\n",
    "highest_probs = np.max(final_probs, axis=1)\n",
    "class_names = le.classes_\n",
    "# ==========================================\n",
    "# SUBMISSION 1: ID + PREDICTED CLASS\n",
    "# ==========================================\n",
    "submission1_df = pd.DataFrame({\n",
    "    'id': test_id,\n",
    "    'fruit_name': decoded_labels\n",
    "})\n",
    "\n",
    "# ==========================================\n",
    "# SUBMISSION 2: ID + ALL CLASS PROBABILITIES log loss jaisa\n",
    "# ==========================================\n",
    "prob_cols = {\n",
    "    f\"Status_{cls}\": final_probs[:, i]\n",
    "    for i, cls in enumerate(class_names)\n",
    "}\n",
    "\n",
    "submission2_df = pd.DataFrame(prob_cols)\n",
    "submission2_df.insert(0, 'id', test_id)\n",
    "\n",
    "# ==========================================\n",
    "# SUBMISSION 3: ID + CLASS + CONFIDENCE random sa kuch to hai\n",
    "# ==========================================\n",
    "submission3_df = pd.DataFrame({\n",
    "    'id': test_id,\n",
    "    'Predicted_Class': decoded_labels,\n",
    "    'Confidence_Score': highest_probs\n",
    "})\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 11: EXPORT FILES 1- for prediction\n",
    "# 2- log loss styled\n",
    "# 3- just all the probablity in one line\n",
    "# ==========================================\n",
    "\n",
    "submission1_df.to_csv(\"submission1.csv\", index=False)\n",
    "submission2_df.to_csv(\"submission2.csv\", index=False)\n",
    "submission3_df.to_csv(\"submission3.csv\", index=False)\n",
    "print(\"All submissions are generated\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
